[{"path":"index.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"scstruc package designed estimate gene regulatory networks (GRNs) single-cell transcriptomics (SCT) data using Bayesian networks (BN). Notably, package focuses following points:Implementation algorithms tailored SCT data characteristics, dropouts (zero-inflation).Evaluating inferred networks based causal validity.Probabilistic reasoning extraction differences regulatory relationships groupsComprehensive visualization understanding resulting GRNs.BN estimate directed relationships genes useful GRN inference. package also supports DAG estimation popular GRN inference software tools, significantly expanding applicability GRNs SCT data analysis.","code":""},{"path":"index.html","id":"installation-and-prerequiresties","chapter":"1 Introduction","heading":"1.1 Installation and prerequiresties","text":"need packages needs installed using full functions scstruc.CCDr algorithm following repository:HurdleNormal package following repository:CCDr algorithm HurdleNormal package, please consult original papers (McDavid et al. 2019; Aragam Zhou 2015).","code":"\ndevtools::install_github(\"noriakis/scstruc\")\ndevtools::install_github(\"itsrainingdata/sparsebnUtils\")\ndevtools::install_github(\"noriakis/ccdrAlgorithm\")\ndevtools::install_github(\"amcdavid/HurdleNormal\")"},{"path":"basic-usage-of-scstruc.html","id":"basic-usage-of-scstruc","chapter":"2 Basic usage of scstruc","heading":"2 Basic usage of scstruc","text":"part present use package inference network evaluation. Basically, object storing (normalized) expression matrix, primary function scstruc can perform inference. use mock data generated scran::mockSCE function .obtain simulated data mockSCE function scuttle, log-normalize count default parameter.","code":"\nlibrary(scran)\nlibrary(scstruc)\nlibrary(ggraph)\nlibrary(bnlearn)\nlibrary(tibble)\nset.seed(0)\nsce <- mockSCE()\nsce <- logNormCounts(sce)\nsce\n#> class: SingleCellExperiment \n#> dim: 2000 200 \n#> metadata(0):\n#> assays(2): counts logcounts\n#> rownames(2000): Gene_0001 Gene_0002 ... Gene_1999\n#>   Gene_2000\n#> rowData names(0):\n#> colnames(200): Cell_001 Cell_002 ... Cell_199\n#>   Cell_200\n#> colData names(4): Mutation_Status Cell_Cycle\n#>   Treatment sizeFactor\n#> reducedDimNames(0):\n#> mainExpName: NULL\n#> altExpNames(1): Spikes"},{"path":"basic-usage-of-scstruc.html","id":"bayesian-network","chapter":"2 Basic usage of scstruc","heading":"2.1 Bayesian network","text":"Bayesian networks probabilistic graphical models represent set random variables \\(X = \\{X_1, \\dots, X_N\\}\\), conditional dependencies using directed acyclic graph (DAG). widely used various domains, economics, medicine, decision-making, modeling complex relationships among variables transcriptomics data. package, infer relationships among genes, representing transcriptional regulation .graphical separation nodes G implies conditional independence corresponding variables leads factorization:\\[\nP(X \\mid G; \\theta) = \\prod_{=1}^{N} P(X_i \\mid \\pi_{X_i}; \\theta_{X_i}) \\quad \\text{} \\pi_{X_i} = \\{ \\text{parents } X_i \\text{ } G \\}\n\\]package, various algorithms implemented tailored account nature SCT data, dropouts.","code":""},{"path":"basic-usage-of-scstruc.html","id":"preprocessing-of-single-cell-transcriptomics-data-and-preparation","chapter":"2 Basic usage of scstruc","heading":"2.2 Preprocessing of single-cell transcriptomics data and preparation","text":"reduce computational burden obtain interpretable results, preprocessing steps preparation suggested.","code":""},{"path":"basic-usage-of-scstruc.html","id":"coarse-graining-expression-data-metacell-expression","chapter":"2 Basic usage of scstruc","heading":"2.2.1 Coarse-graining expression data (metacell expression)","text":"package can use metacell approach reduce computational burden required perform structure learning SCT data. package features superCellMat function using SuperCell package available CRAN. employs cell aggregation approach reduce dataset complexity preserving key biological variability　(Bilous et al. 2022). step optional one can use untransformed data directly.","code":"\nlibrary(SuperCell)\ndim(sce)\n#> [1] 2000  200\nrowData(sce)[\"ID\"] <- row.names(sce)\nsce <- superCellMat(sce, ID=\"ID\")\n#>    2000 20\ndim(sce)\n#> [1] 2000   20"},{"path":"basic-usage-of-scstruc.html","id":"obtaining-interesting-gene-identifiers","chapter":"2 Basic usage of scstruc","heading":"2.2.2 Obtaining interesting gene identifiers","text":"inference, first subset genes interesting biological pathway (ECM receptor interaction cells annotated vascular endothelial cells). purpose, two functions prepared. One fetching gene identifiers Gene Ontology, another KEGG PATHWAY.","code":""},{"path":"basic-usage-of-scstruc.html","id":"getgogenes","chapter":"2 Basic usage of scstruc","heading":"2.2.2.1 getGOGenes","text":"can obtain genes involved gene ontology using identifier.","code":"\nlibrary(scstruc)\nlibrary(org.Mm.eg.db)\ngenes <- getGOGenes(\"GO:0030198\", orgDb=org.Mm.eg.db)\ngenes[1:5]\n#> [1] \"Abl1\"    \"Abl1\"    \"Abl2\"    \"Adamts1\" \"Adamts1\""},{"path":"basic-usage-of-scstruc.html","id":"getkeggpathwaygenes","chapter":"2 Basic usage of scstruc","heading":"2.2.2.2 getKEGGPathwayGenes","text":"can obtain genes involved KEGG PATHWAY using KEGG identifier organism identifier. obtaining genes involved mTOR signaling pathway Mus musculus. need specify organism database order correcrly convert obtained identifiers.can pass genes inference scstruc function. Also, published package estimates GRNs omics data based enrichment analysis results past, approach useful (Sato et al. 2022).","code":"\nlibrary(KEGGREST)\ngenes <- getKEGGPathwayGenes(\"mmu04150\", orgDb=org.Mm.eg.db)\ngenes[1:5]\n#> [1] \"Prkaa1\"  \"Prkaa2\"  \"Atp6v1h\" \"Prr5\"    \"Braf\""},{"path":"basic-usage-of-scstruc.html","id":"actual-structure-learning","chapter":"2 Basic usage of scstruc","heading":"2.3 Actual structure learning","text":"scstruc function needs SingleCellExperiment object storing gene expression data. Also, gene list must specified. analysis, randomly subset gene identifiers used input. changeSymbol argument refers changing gene names subset matrix specified symbolColumn argument (default Symbol). example, corresponding symbol argument set FALSE. Also, algorithm set mmhc default, performs max-min hill climbing approach.default, returns bn object bnlearn actual data used inference. returnBn set FALSE, function returns tidygraph object. can used various downstream tasks, visualization, probabilistic reasoning, evaluation based biological pathway information. details including use various algorithms learning described following sections.","code":"\nincluded_genes <- sample(row.names(sce), 100)\ngs <- scstruc(sce, included_genes, changeSymbol=FALSE)\nnames(gs)\n#> [1] \"net\"  \"data\"\ngs$net\n#> \n#>   Bayesian network learned via Hybrid methods\n#> \n#>   model:\n#>    [Gene_0019][Gene_0061][Gene_0097][Gene_0099][Gene_0101]\n#>    [Gene_0108][Gene_0123][Gene_0198][Gene_0224][Gene_0239]\n#>    [Gene_0242][Gene_0290][Gene_0292][Gene_0322][Gene_0325]\n#>    [Gene_0332][Gene_0352][Gene_0354][Gene_0374][Gene_0418]\n#>    [Gene_0433][Gene_0451][Gene_0630][Gene_0642][Gene_0676]\n#>    [Gene_0744][Gene_0750][Gene_0795][Gene_0831][Gene_0900]\n#>    [Gene_1018][Gene_1024][Gene_1030][Gene_1048][Gene_1124]\n#>    [Gene_1144][Gene_1178][Gene_1180][Gene_1241][Gene_1273]\n#>    [Gene_1283][Gene_1316][Gene_1342][Gene_1512][Gene_1646]\n#>    [Gene_1672][Gene_1795][Gene_1889][Gene_1976]\n#>    [Gene_0238|Gene_0019:Gene_0795][Gene_0466|Gene_0224]\n#>    [Gene_0558|Gene_0322][Gene_0580|Gene_0332]\n#>    [Gene_0711|Gene_0433:Gene_0795:Gene_1273]\n#>    [Gene_0716|Gene_0676][Gene_0772|Gene_0354]\n#>    [Gene_0840|Gene_0642][Gene_0859|Gene_0744]\n#>    [Gene_0954|Gene_0642][Gene_0979|Gene_0325]\n#>    [Gene_0980|Gene_0433][Gene_1059|Gene_0290]\n#>    [Gene_1084|Gene_0101][Gene_1132|Gene_1030]\n#>    [Gene_1173|Gene_0097:Gene_1512][Gene_1310|Gene_0292]\n#>    [Gene_1360|Gene_1024][Gene_1372|Gene_1048]\n#>    [Gene_1384|Gene_0433][Gene_1483|Gene_1018:Gene_1273]\n#>    [Gene_1487|Gene_1030:Gene_1672][Gene_1509|Gene_0292]\n#>    [Gene_1542|Gene_1342][Gene_1642|Gene_1178:Gene_1241]\n#>    [Gene_1677|Gene_1180:Gene_1889][Gene_1739|Gene_0676]\n#>    [Gene_1751|Gene_1646][Gene_1775|Gene_1316]\n#>    [Gene_1855|Gene_0108][Gene_1859|Gene_0831:Gene_1144]\n#>    [Gene_1863|Gene_0630][Gene_1982|Gene_0061]\n#>    [Gene_0427|Gene_0108:Gene_1059][Gene_0792|Gene_1360]\n#>    [Gene_1257|Gene_1863][Gene_1262|Gene_0900:Gene_1855]\n#>    [Gene_1518|Gene_0451:Gene_1982][Gene_1519|Gene_1084]\n#>    [Gene_1653|Gene_0772][Gene_1804|Gene_1775]\n#>    [Gene_0048|Gene_0198:Gene_1804][Gene_0617|Gene_1257]\n#>    [Gene_0786|Gene_0427][Gene_1159|Gene_0792]\n#>    [Gene_1742|Gene_0792][Gene_0398|Gene_0786]\n#>    [Gene_0463|Gene_0786:Gene_1342]\n#>    [Gene_0490|Gene_0352:Gene_1159:Gene_1283]\n#>    [Gene_1140|Gene_1742][Gene_1991|Gene_1140]\n#>   nodes:                                 100 \n#>   arcs:                                  67 \n#>     undirected arcs:                     0 \n#>     directed arcs:                       67 \n#>   average markov blanket size:           1.70 \n#>   average neighbourhood size:            1.34 \n#>   average branching factor:              0.67 \n#> \n#>   learning algorithm:                    \n#>                                         Max-Min Hill-Climbing \n#>   constraint-based method:               \n#>                                       Max-Min Parent Children \n#>   conditional independence test:         \n#>                                         Pearson's Correlation \n#>   score-based method:                    Hill-Climbing \n#>   score:                                 BIC (Gauss.) \n#>   alpha threshold:                       0.05 \n#>   penalization coefficient:              1.497866 \n#>   tests used in the learning procedure:  22042 \n#>   optimized:                             TRUE"},{"path":"penalized-regressions.html","id":"penalized-regressions","chapter":"3 Penalized regressions","heading":"3 Penalized regressions","text":"Penalized regression type regression analysis includes penalty term prevent overfitting improve generalizability model. particularly useful dealing high-dimensional data number predictors large compared number observations. terms inference GRN BN structure learning, penalized regression used successfully (Schmidt, Niculescu-Mizil, Murphy 2007). package implments core algorithms use penalization BN structure learning described .","code":""},{"path":"penalized-regressions.html","id":"algorithms","chapter":"3 Penalized regressions","heading":"3.1 Algorithms","text":"","code":""},{"path":"penalized-regressions.html","id":"glmnet_bic-and-glmnet_cv","chapter":"3 Penalized regressions","heading":"3.1.1 glmnet_BIC and glmnet_CV","text":"L1 regularization (LASSO), package uses popular R library glmnet. glmnet_BIC specified argument algo select lambda minimum BIC criteria, glmnet_CV choose lambda based cross validation specified fold numbers. glmnetBICpath returns BIC path given data.frame node name modeled. plot contains BIC path plot, fit contains fitted object BIC lambda BIC data.frame. maximize function can chosen maximize argument algorithm.args list. Greedy Equivalence Search can performed via setting argument ges.","code":"\nlibrary(scran)\nlibrary(scstruc)\nlibrary(bnlearn)\n\nsce <- mockSCE()\nsce <- logNormCounts(sce)\nincluded_genes <- sample(row.names(sce), 30)\n\n## Inference based on glmnet_CV and maximization by GES\ngs <- scstruc(sce, included_genes,\n    algorithm=\"glmnet_CV\",\n    algorithm.args=list(\"maximize\"=\"ges\"),\n    changeSymbol=FALSE)\ngs$net\n#> \n#>   Random/Generated Bayesian network\n#> \n#>   model:\n#>    [Gene_0060][Gene_0069][Gene_0230][Gene_0281][Gene_0541]\n#>    [Gene_0606][Gene_0607][Gene_0659][Gene_0857][Gene_0969]\n#>    [Gene_0991][Gene_0992][Gene_1036][Gene_1060][Gene_1063]\n#>    [Gene_1065][Gene_1071][Gene_1195][Gene_1321][Gene_1322]\n#>    [Gene_1375][Gene_1430][Gene_1496][Gene_1724][Gene_1784]\n#>    [Gene_0645|Gene_0659:Gene_1071][Gene_1256|Gene_0060]\n#>    [Gene_1270|Gene_1195][Gene_1454|Gene_1195]\n#>    [Gene_0410|Gene_0645]\n#>   nodes:                                 30 \n#>   arcs:                                  6 \n#>     undirected arcs:                     0 \n#>     directed arcs:                       6 \n#>   average markov blanket size:           0.47 \n#>   average neighbourhood size:            0.40 \n#>   average branching factor:              0.20 \n#> \n#>   generation algorithm:                  Empty\n\n## Visualization of glmnet_BIC criteria\n## Just to obtain data to be used in the inference\ngs <- scstruc(sce, included_genes,\n    changeSymbol=FALSE, returnData=TRUE)\n\nset.seed(10)\nglmnetBICpath(gs$data, sample(colnames(gs$data), 1))[[\"plot\"]]"},{"path":"penalized-regressions.html","id":"mcp_cv-and-scad_cv","chapter":"3 Penalized regressions","heading":"3.1.2 MCP_CV and SCAD_CV","text":"glmnet_CV, library performs penalized regression baed MCP SCAD using ncvreg library.","code":"\nlibrary(ncvreg)\n\nmcp.net <- scstruc(sce, included_genes,\n    algorithm=\"MCP_CV\", returnData=FALSE,\n    changeSymbol=FALSE)\n\nscad.net <- scstruc(sce, included_genes,\n    algorithm=\"SCAD_CV\", returnData=FALSE,\n    changeSymbol=FALSE)\n\n## Using the bnlearn function to compare two networks\nbnlearn::compare(mcp.net, scad.net)\n#> $tp\n#> [1] 1\n#> \n#> $fp\n#> [1] 3\n#> \n#> $fn\n#> [1] 0"},{"path":"penalized-regressions.html","id":"l0-regularized-regression","chapter":"3 Penalized regressions","heading":"3.1.3 L0-regularized regression","text":"Based L0Learn, package performs structure learning based L0-regularized regression. L0 regularization, also known best subset selection, technique used build simpler interpretable models selecting small number important variables. L0L1 L0L2 regularization combination L0, L1, L2 regularization. details L0-, L0L1-, L0L2-regularized regression, please consult original paper (Hazimeh, Mazumder, Nonet 2023).","code":"\nl0l2.net <- scstruc(sce, included_genes,\n    algorithm=\"L0L2_CV\", returnData=FALSE,\n    changeSymbol=FALSE)\nplotNet(l0l2.net)"},{"path":"penalized-regressions.html","id":"ccdr-algorithm","chapter":"3 Penalized regressions","heading":"3.1.4 CCDr algorithm","text":"Generally, CCDr algorithm fastest algorithm learns network multiple lambdas. default, function chooses network best BIC value among multiple lambdas. supress effect obtain networks, set bestScore FALSE algorithm.args.Therefore, bootstrap-based inference can performed fast using CCDr algorithm. bootstrapping specified, function performs learning bootstrapped network multiple lambdas across replicates.","code":"\nlibrary(ccdrAlgorithm);library(sparsebnUtils)\nccdr.res <- scstruc(sce, included_genes,\n    algorithm=\"ccdr\", changeSymbol=FALSE,\n    algorithm.args=list(bestScore=FALSE))\n#> Setting `lambdas.length` to 10\n#> Returning the bn per lambda from result of ccdr.run\nnames(ccdr.res$net)\n#> [1] \"14.1421356237309\"  \"8.47798757230114\" \n#> [3] \"5.08242002399425\"  \"3.04683075789017\" \n#> [5] \"1.82652705274248\"  \"1.09497420090059\" \n#> [7] \"0.656419787945471\" \"0.393513324471009\"\nccdr.res$net[[4]]\n#> \n#>   Random/Generated Bayesian network\n#> \n#>   model:\n#>    [Gene_0060][Gene_0069][Gene_0230][Gene_0281][Gene_0410]\n#>    [Gene_0541][Gene_0606][Gene_0607][Gene_0645][Gene_0659]\n#>    [Gene_0857][Gene_0969][Gene_0991][Gene_0992][Gene_1036]\n#>    [Gene_1060][Gene_1063][Gene_1065][Gene_1071][Gene_1195]\n#>    [Gene_1256][Gene_1270][Gene_1321][Gene_1322][Gene_1375]\n#>    [Gene_1430][Gene_1454][Gene_1496][Gene_1724][Gene_1784]\n#>   nodes:                                 30 \n#>   arcs:                                  0 \n#>     undirected arcs:                     0 \n#>     directed arcs:                       0 \n#>   average markov blanket size:           0.00 \n#>   average neighbourhood size:            0.00 \n#>   average branching factor:              0.00 \n#> \n#>   generation algorithm:                  Empty"},{"path":"penalized-regressions.html","id":"precision-lasso","chapter":"3 Penalized regressions","heading":"3.1.5 Precision lasso","text":"Precision Lasso combines LASSO precision matrix regularization process. approach particularly useful biological genomics studies, highly-correlated features often appear. implmented precision lasso R feature provided plasso.fit plasso.fit.single using RcppArmadillo. fixed lambda value specified.","code":"\npl.res <- scstruc(sce, included_genes, algorithm=\"plasso\", changeSymbol=FALSE)"},{"path":"hurdle-model.html","id":"hurdle-model","chapter":"4 Hurdle model","heading":"4 Hurdle model","text":"handling zero-inflated nature single-cell transcriptomics data, use hurdle model presented. hurdle model two-part model models whether observation zero , non-zero part separately.Based inferred network HurdleNormal, proposed multivariate Hurdle model grouped lasso learn undirected network (McDavid et al. 2019), directed acyclic graph inferred based score maximization using constraints. undirected network selected multiple lambdas based BIC criteria implemented HurdleNormal. function, Hurdle algorithm specified algorithm argument scstruc. default, score BIC bnlearn.score maximization function can set arbitrarily (maximizeFun), set hc default. Greedy Equivalence Search can performed via setting maximize argument ges.","code":"\nlibrary(HurdleNormal)\nlibrary(scstruc)\n\nsce <- mockSCE()\nsce <- logNormCounts(sce)\nincluded_genes <- sample(row.names(sce), 20)\ngs <- scstruc(sce, included_genes,\n    changeSymbol=FALSE, algorithm=\"Hurdle\")\ngs$net\n#> \n#>   Bayesian network learned via Score-based methods\n#> \n#>   model:\n#>    [Gene_0013][Gene_0072][Gene_0347][Gene_0377][Gene_0516]\n#>    [Gene_0535][Gene_0633][Gene_0638][Gene_0708][Gene_0858]\n#>    [Gene_0860][Gene_0914][Gene_0932][Gene_0951][Gene_1079]\n#>    [Gene_1268][Gene_1586][Gene_1655][Gene_1905][Gene_1972]\n#>   nodes:                                 20 \n#>   arcs:                                  0 \n#>     undirected arcs:                     0 \n#>     directed arcs:                       0 \n#>   average markov blanket size:           0.00 \n#>   average neighbourhood size:            0.00 \n#>   average branching factor:              0.00 \n#> \n#>   learning algorithm:                    Hill-Climbing \n#>   score:                                 BIC (Gauss.) \n#>   penalization coefficient:              2.649159 \n#>   tests used in the learning procedure:  0 \n#>   optimized:                             TRUE\ngs.tabu <- scstruc(sce, included_genes,\n    changeSymbol=FALSE, algorithm=\"Hurdle\",\n    algorithm.args=list(maximizeFun=bnlearn::tabu))\ngs.tabu$net\n#> \n#>   Bayesian network learned via Score-based methods\n#> \n#>   model:\n#>    [Gene_0013][Gene_0072][Gene_0347][Gene_0377][Gene_0516]\n#>    [Gene_0535][Gene_0633][Gene_0638][Gene_0708][Gene_0858]\n#>    [Gene_0860][Gene_0914][Gene_0932][Gene_0951][Gene_1079]\n#>    [Gene_1268][Gene_1586][Gene_1655][Gene_1905][Gene_1972]\n#>   nodes:                                 20 \n#>   arcs:                                  0 \n#>     undirected arcs:                     0 \n#>     directed arcs:                       0 \n#>   average markov blanket size:           0.00 \n#>   average neighbourhood size:            0.00 \n#>   average branching factor:              0.00 \n#> \n#>   learning algorithm:                    Tabu Search \n#>   score:                                 BIC (Gauss.) \n#>   penalization coefficient:              2.649159 \n#>   tests used in the learning procedure:  0 \n#>   optimized:                             TRUE\n## This performs GES\ngs.ges <- scstruc(sce, included_genes,\n    changeSymbol=FALSE, algorithm=\"Hurdle\",\n    algorithm.args=list(maximize=\"ges\"))\ngs.ges$net\n#> \n#>   Random/Generated Bayesian network\n#> \n#>   model:\n#>    [Gene_0013][Gene_0072][Gene_0347][Gene_0377][Gene_0516]\n#>    [Gene_0535][Gene_0633][Gene_0638][Gene_0708][Gene_0858]\n#>    [Gene_0860][Gene_0914][Gene_0932][Gene_0951][Gene_1079]\n#>    [Gene_1268][Gene_1586][Gene_1655][Gene_1905][Gene_1972]\n#>   nodes:                                 20 \n#>   arcs:                                  0 \n#>     undirected arcs:                     0 \n#>     directed arcs:                       0 \n#>   average markov blanket size:           0.00 \n#>   average neighbourhood size:            0.00 \n#>   average branching factor:              0.00 \n#> \n#>   generation algorithm:                  Empty"},{"path":"hurdle-model.html","id":"customized-score-for-hurdle-model","chapter":"4 Hurdle model","heading":"4.1 Customized score for hurdle model","text":"Additional score can specified using hurdle.bic function algorithm.args argument. score defined sum BIC values continuous logistic regression part hurdle model. Let \\(Y = [y_{ij}]\\) denote log-normalized expression value gene subset cell j \\(Z = [z_{ij}]\\) 0-1 indicator value whether gene expression zero. score defined :\\[\n\\text{logit}\\left(\\Pr(Z_{ij} = 1)\\right) \\sim \\beta_i G_j,\n\\]\\[\n\\Pr(Y_{ij} = y \\mid Z_{ij} = 1) \\sim N(\\beta_i G_j, \\sigma^2).\n\\]proposed MAST library, cellular detection rate adjustment (CDR) can performed scoring phase cdrAdjuetment TRUE. applies inclusion CDR term hurdle modeling score maximizing phase.","code":"\ngs2 <- scstruc(sce, included_genes,\n    changeSymbol=FALSE, algorithm=\"Hurdle\",\n    algorithm.args=list(\"score\"=hurdle.bic))\ngs2$net\n#> \n#>   Bayesian network learned via Score-based methods\n#> \n#>   model:\n#>    [Gene_0013][Gene_0072][Gene_0347][Gene_0377][Gene_0516]\n#>    [Gene_0535][Gene_0633][Gene_0638][Gene_0708][Gene_0858]\n#>    [Gene_0860][Gene_0914][Gene_0932][Gene_0951][Gene_1079]\n#>    [Gene_1268][Gene_1586][Gene_1655][Gene_1905][Gene_1972]\n#>   nodes:                                 20 \n#>   arcs:                                  0 \n#>     undirected arcs:                     0 \n#>     directed arcs:                       0 \n#>   average markov blanket size:           0.00 \n#>   average neighbourhood size:            0.00 \n#>   average branching factor:              0.00 \n#> \n#>   learning algorithm:                    Hill-Climbing \n#>   score:                                 \n#>                                  User-Provided Score Function \n#>   tests used in the learning procedure:  0 \n#>   optimized:                             TRUE"},{"path":"other-algorithms-and-software.html","id":"other-algorithms-and-software","chapter":"5 Other algorithms and software","heading":"5 Other algorithms and software","text":"","code":""},{"path":"other-algorithms-and-software.html","id":"bootstrapping","chapter":"5 Other algorithms and software","heading":"5.1 Bootstrapping","text":"obtaining reliable network, can use bootstrapping approach randomly subsampling data, infer network , average bootstrapped networks. algorithms can use bootstrapping specifying boot=TRUE. instance, use bootstrapping CCDr algorithm (fast), example codes shown . Replication number can specified R sampling number can specified m argument. way, bn.strength object returned net.","code":"\nlibrary(scstruc)\n\nsce <- mockSCE()\nsce <- logNormCounts(sce)\nincluded_genes <- sample(row.names(sce), 40)\ngs <- scstruc(sce, included_genes, R=30,\n              changeSymbol=FALSE, algorithm=\"ccdr\", boot=TRUE)\n#> Bootstrapping specified\n#> Returning the list of bn.strength\n\n## It consists of strength from multiple lambdas\nhead(gs$net[[5]])\n#>        from        to strength direction\n#> 1 Gene_0136 Gene_0302        0         0\n#> 2 Gene_0136 Gene_0307        0         0\n#> 3 Gene_0136 Gene_0350        0         0\n#> 4 Gene_0136 Gene_0392        0         0\n#> 5 Gene_0136 Gene_0401        0         0\n#> 6 Gene_0136 Gene_0457        0         0"},{"path":"other-algorithms-and-software.html","id":"pidc","chapter":"5 Other algorithms and software","heading":"5.2 PIDC","text":"PIDC algorithm based information theory leverages partial information decomposition (PID) analyze quantify relationships multiple variables (Chan, Stumpf, Babtie 2017). scstruc uses undirected network produced PIDC, implemented Julia. JuliaCall used call Julia R, users first set Julia environment. Also, path main library (NetworkInference.jl) specified NetworkInference_HOME argument. directed acyclic graph obtained based score maximization constraints produced PIDC. example code shown follows:bootstrapped-based inference can also performed. case, averaged network obtained per thresholds parameters algorithm.args. default, network thresholded seq(0.1, 0.4, 0.1).maximization can chosen scoring function available bnlearn Greedy Equivalence Search (ges), can specified parameter maximize algorithm.args.Note raw network output scaled thresholded stored temporary directory.","code":"\nlibrary(JuliaCall)\njulia <- julia_setup(JULIA_HOME = \"./Julia-1.10.5/bin\")\ngs <- scstruc(sce, included_genes,\n              changeSymbol=FALSE,\n              algorithm=\"pidc\",\n              algorithm.args=list(NetworkInference_HOME=\"./NetworkInference.jl\"))\ngs$net\ngs <- scstruc(sce, included_genes,\n              changeSymbol=FALSE,\n              algorithm=\"pidc\", boot=TRUE, R=30,\n              algorithm.args=list(NetworkInference_HOME=\"./NetworkInference.jl\"))\ngs$net"},{"path":"other-algorithms-and-software.html","id":"genie3","chapter":"5 Other algorithms and software","heading":"5.3 GENIE3","text":"GENIE3 widely used method inferring directed interactions genes based ensemble regression trees. specifying genie3 algorithm, function performs GENIE3 algorithm subsequently threshold arcs. , function returns list original results networks thresholded network DAG.","code":"\ngs <- scstruc(sce, included_genes,\n              changeSymbol=FALSE,\n              algorithm=\"genie3\")\nhead(gs$net$original)\n#>             Gene_0136  Gene_0302  Gene_0307   Gene_0350\n#> Gene_0136 0.000000000 0.03815198 0.03033649 0.041082345\n#> Gene_0302 0.038278390 0.00000000 0.04384009 0.027663166\n#> Gene_0307 0.030111652 0.03673630 0.00000000 0.032976816\n#> Gene_0350 0.016747356 0.01259568 0.01475499 0.000000000\n#> Gene_0392 0.009417026 0.00905313 0.02542493 0.007675829\n#> Gene_0401 0.026928721 0.03057284 0.02406323 0.023513165\n#>            Gene_0392  Gene_0401   Gene_0457   Gene_0604\n#> Gene_0136 0.04648226 0.02337528 0.026669667 0.030160030\n#> Gene_0302 0.02192453 0.02674055 0.029739473 0.032546259\n#> Gene_0307 0.06882408 0.02316867 0.028509166 0.036082195\n#> Gene_0350 0.01194514 0.01299722 0.013846909 0.017583805\n#> Gene_0392 0.00000000 0.01883923 0.009379975 0.009928166\n#> Gene_0401 0.03699605 0.00000000 0.026166402 0.025136633\n#>             Gene_0713   Gene_0750  Gene_0864  Gene_0896\n#> Gene_0136 0.025855796 0.021457870 0.02811444 0.02466951\n#> Gene_0302 0.024273916 0.023555467 0.03804105 0.03145132\n#> Gene_0307 0.046605300 0.025364098 0.02651592 0.02677376\n#> Gene_0350 0.012690999 0.012314518 0.01280650 0.01707095\n#> Gene_0392 0.009130004 0.006187762 0.01058934 0.00804439\n#> Gene_0401 0.030871800 0.032225826 0.02977111 0.03693539\n#>            Gene_0900  Gene_0952   Gene_1019   Gene_1027\n#> Gene_0136 0.02664938 0.02794521 0.050803463 0.025559635\n#> Gene_0302 0.02333425 0.02743567 0.028156731 0.022775713\n#> Gene_0307 0.04213985 0.04642870 0.033456730 0.030720022\n#> Gene_0350 0.02097608 0.03077974 0.013197604 0.009960530\n#> Gene_0392 0.01831480 0.00720375 0.009492629 0.005857273\n#> Gene_0401 0.02755639 0.02627090 0.023445935 0.027167016\n#>             Gene_1044   Gene_1099   Gene_1141   Gene_1147\n#> Gene_0136 0.030426695 0.031965744 0.019138151 0.030471918\n#> Gene_0302 0.029496119 0.046808942 0.013459680 0.028850265\n#> Gene_0307 0.030023075 0.053413942 0.053407348 0.036376766\n#> Gene_0350 0.014516524 0.015075026 0.007550333 0.013949234\n#> Gene_0392 0.008448556 0.006533706 0.005959179 0.008713158\n#> Gene_0401 0.048214400 0.027910790 0.035217399 0.046985978\n#>             Gene_1212   Gene_1270   Gene_1313   Gene_1357\n#> Gene_0136 0.022230224 0.028804101 0.022075456 0.021049147\n#> Gene_0302 0.029052077 0.023988628 0.040953583 0.015107704\n#> Gene_0307 0.046269274 0.040661734 0.025518922 0.027737605\n#> Gene_0350 0.014653098 0.017480964 0.008155586 0.011108790\n#> Gene_0392 0.005272744 0.007265429 0.024178523 0.009322583\n#> Gene_0401 0.041266070 0.025051974 0.024298585 0.020992240\n#>             Gene_1362   Gene_1448  Gene_1449   Gene_1456\n#> Gene_0136 0.024161605 0.044487650 0.03141692 0.027353634\n#> Gene_0302 0.036407367 0.027787208 0.03280477 0.035540784\n#> Gene_0307 0.033298731 0.042767262 0.03369469 0.032973421\n#> Gene_0350 0.029097022 0.012382960 0.01976695 0.016965853\n#> Gene_0392 0.005977574 0.009708553 0.01339975 0.006919641\n#> Gene_0401 0.031397431 0.045816305 0.04198381 0.051922271\n#>             Gene_1459  Gene_1509   Gene_1521   Gene_1677\n#> Gene_0136 0.023175863 0.03086472 0.028955898 0.030377296\n#> Gene_0302 0.029205700 0.03027946 0.045265261 0.024402367\n#> Gene_0307 0.033317710 0.04266091 0.032629080 0.038115352\n#> Gene_0350 0.020894528 0.04888214 0.016485845 0.012038425\n#> Gene_0392 0.008546227 0.01131372 0.009456666 0.007903083\n#> Gene_0401 0.029065808 0.03615510 0.022199438 0.027399003\n#>             Gene_1743   Gene_1766   Gene_1822  Gene_1841\n#> Gene_0136 0.026207363 0.037843780 0.028362633 0.04885591\n#> Gene_0302 0.022705805 0.031373235 0.028968008 0.02407048\n#> Gene_0307 0.037131385 0.032466744 0.027821938 0.03447045\n#> Gene_0350 0.031977465 0.014364427 0.016248574 0.02234902\n#> Gene_0392 0.008937382 0.008547491 0.006495196 0.01031908\n#> Gene_0401 0.071085403 0.028437538 0.038390071 0.03079519\n#>             Gene_1885   Gene_1893  Gene_1903  Gene_1906\n#> Gene_0136 0.028342254 0.030577202 0.02564471 0.03109586\n#> Gene_0302 0.032120416 0.043366644 0.02661660 0.03050130\n#> Gene_0307 0.032491832 0.027815304 0.05801220 0.03257176\n#> Gene_0350 0.017024285 0.029956807 0.01982418 0.01370361\n#> Gene_0392 0.006693124 0.009723063 0.01181725 0.00840537\n#> Gene_0401 0.044197370 0.030558183 0.02218325 0.03685088"},{"path":"evaluating-the-inferred-networks.html","id":"evaluating-the-inferred-networks","chapter":"6 Evaluating the inferred networks","heading":"6 Evaluating the inferred networks","text":"interpretation results, assessment inferred networks crucial. necessary determine network used downstream analysis, assess closely inferred causal relationships resemble biologically validated networks. One core features scstruc evaluating selecting optimal algorithms inferred networks. describe evaluate inferred networks using various metrics section. implemented metrics include:True positive arcsFalse positive arcsFalse negative arcsPrecisionRecallF1-scoreBayesian Information Criterion (data fitted provided)Structural Hamming DistanceStructural Intervention Distance (without symmetrization)Kullback–Leibler divergenceAUPRC (bootstrapped network )","code":""},{"path":"evaluating-the-inferred-networks.html","id":"evaluation-functions","chapter":"6 Evaluating the inferred networks","heading":"6.1 Evaluation functions","text":"","code":""},{"path":"evaluating-the-inferred-networks.html","id":"metrics-function","chapter":"6 Evaluating the inferred networks","heading":"6.1.1 metrics function","text":"function accepts learned networks reference network (bn object) outputs data.frame consisting various metrics.sid_sym argument can choose whether symmetrze SID, SID.cran can choose whether use SID implemented CRAN package SID.","code":"\nlibrary(scstruc)\nnet <- readRDS(\"ecoli70.rds\")\ndata.inference <- rbn(net, 50)\ninfer <- hc(data.inference)\nmetrics(bn.net(net), list(\"inferred\"=infer))\n#>       algo referenceNode InferenceNode s0 edges SHD TP FP\n#> 1 inferred            46            46 70   106 112 29 41\n#>   FN       TPR Precision    Recall        F1  SID KL BIC\n#> 1 77 0.4142857 0.4142857 0.2735849 0.3295455 1061 NA  NA"},{"path":"evaluating-the-inferred-networks.html","id":"metricsfromfitted-function","chapter":"6 Evaluating the inferred networks","heading":"6.1.2 metricsFromFitted function","text":"function accepts parameter-fitted network sampling number, well algorithms used inference. Using rbn function bnlearn, logic sampling performed fitted network. , use ECOLI70 network GeneNet R package, sampling 50 observations network. testing algorithms can specifed argument algos. special algorithms, arguments name provided. function return_data return_net argument, returns data used inference inferred networks. default, metrics returned.results can visualized usual way using library like ggplot2. use plotthis library visualizing.","code":"\nmf <- metricsFromFitted(net, 50, algos=c(\"glmnet_CV\", \"glmnet_BIC\", \"L0_CV\"))\n#> glmnet_CV 12.1235988140106\n#> glmnet_BIC 0.902992010116577\n#> L0_CV\n#> 10.8184690475464\n#> MMHC 0.001 0.118052959442139\n#> MMHC 0.005 0.0820488929748535\n#> MMHC 0.01 0.0785148143768311\n#> MMHC 0.05 0.0989677906036377\n#> Network computing finished\nhead(mf$metrics)\n#>         algo s0 edges       KL       BIC SHD TP FP FN\n#> 1  glmnet_CV 70    59 12.58813 -2418.812  77 23 47 36\n#> 2 glmnet_BIC 70    39 16.74091 -2501.538  53 22 48 17\n#> 3      L0_CV 70    30 83.81795 -2993.413  74  8 62 22\n#> 4 mmhc_0.001 70    25 53.17069 -2829.217  59 12 58 13\n#> 5 mmhc_0.005 70    26 53.08280 -2826.306  59 13 57 13\n#> 6  mmhc_0.01 70    29 36.29393 -2710.490  58 15 55 14\n#>         TPR Precision    Recall        F1 SID PPI\n#> 1 0.3285714 0.3285714 0.3898305 0.3565891  NA  NA\n#> 2 0.3142857 0.3142857 0.5641026 0.4036697  NA  NA\n#> 3 0.1142857 0.1142857 0.2666667 0.1600000  NA  NA\n#> 4 0.1714286 0.1714286 0.4800000 0.2526316  NA  NA\n#> 5 0.1857143 0.1857143 0.5000000 0.2708333  NA  NA\n#> 6 0.2142857 0.2142857 0.5172414 0.3030303  NA  NA\n#>          time   BICnorm  N  p\n#> 1 12.12359881 0.9389295 50 46\n#> 2  0.90299201 0.8854144 50 46\n#> 3 10.81846905 0.5672219 50 46\n#> 4  0.11805296 0.6734400 50 46\n#> 5  0.08204889 0.6753229 50 46\n#> 6  0.07851481 0.7502440 50 46\nlibrary(plotthis)\nlibrary(ggplot2)\nlibrary(ggrepel)\nScatterPlot(mf$metrics, x=\"SHD\", y=\"F1\", color_by=\"algo\", legend.position=\"none\") +\n    geom_text_repel(aes(label=algo), bg.colour=\"white\")"},{"path":"evaluating-the-inferred-networks.html","id":"evaluating-the-causal-validity","chapter":"6 Evaluating the inferred networks","heading":"6.2 Evaluating the causal validity","text":"primary objective package evaluating causal validity inferred networks. Two approach can used, situations reference directed network available . cases, reference networks readily available.","code":""},{"path":"evaluating-the-inferred-networks.html","id":"obtaining-the-directed-acyclic-graphs-dags-for-the-evaluation","chapter":"6 Evaluating the inferred networks","heading":"6.2.1 Obtaining the directed acyclic graphs (DAGs) for the evaluation","text":"interesting biological pathway, one can obtain DAG KEGG PATHWAY. getKEGGEdges function accepts pathway identifier returns DAG, though always succeed. function first parses pathway information using ggkegg, identify largest components evaluated. removeCycle TRUE, function identifies minimum feedback using igraph function remove edges. returns bn object.Suppose interested inferring gene regulatory networks mTOR signaling pathway dataset, first load DAG KEGG API.Using genes candidate pathway, inference performed performance metrics can obtained based reference DAG.","code":"\nlibrary(scstruc)\ndags <- getKEGGEdges(\"mmu04150\", removeCycle=TRUE)\n#> Removing Pik3ca|Mtor\ngraphviz.plot(dags)\nmymet <- metrics(dags, list(\"Algo1\"=net))"},{"path":"evaluating-the-inferred-networks.html","id":"intersection-validation-approach","chapter":"6 Evaluating the inferred networks","heading":"6.2.2 Intersection-Validation approach","text":"case reference networks, can use Insersection-Validation approach, proposed Viinikka et al. (Viinikka, Eggeling, Koivisto 2018) evaluate algorithm optimal terms SHD SID. purpose, interVal function prepared. function accepts input data, multiple algorithms tested, parameters related Intersection-Validation. implemented metrics SHD SID.user provide data algorithms tested,r argument used specify iteration number, ss argument used specify sub-sampling number. leaves message connected node pairs, defined number edges agreement graph, 15. returnA0 option can used return intersection inferred networks first stage. output option can specified output relevant data (data used inference, A0, bn object).","code":"\ntest.data <- head(gaussian.test, 50)\ntest <- interVal(test.data, algos=c(\"hc\",\"mmhc\",\"tabu\"), ss=30)\ntest\n#> $A0\n#> \n#>   Random/Generated Bayesian network\n#> \n#>   model:\n#>    [A][B][C][D][E][G][F|E:G] \n#>   nodes:                                 7 \n#>   arcs:                                  2 \n#>     undirected arcs:                     0 \n#>     directed arcs:                       2 \n#>   average markov blanket size:           0.86 \n#>   average neighbourhood size:            0.57 \n#>   average branching factor:              0.29 \n#> \n#>   generation algorithm:                  Empty \n#> \n#> \n#> $stat\n#> # A tibble: 3 × 4\n#>   AlgoNum SHD.stat SID.stat    en\n#>     <dbl>    <dbl>    <dbl> <dbl>\n#> 1       1      5.2      0     7.2\n#> 2       2      2.7      1.5   2.3\n#> 3       3      5.4      0     7.4\n#> \n#> $raw.stat\n#>     R AlgoNum SHD SID EdgeNumber\n#> 1   1       1   6   0          8\n#> 2   1       2   1   0          3\n#> 3   1       3   6   0          8\n#> 4   2       1   6   0          8\n#> 5   2       2   3   3          2\n#> 6   2       3   6   0          8\n#> 7   3       1   4   0          6\n#> 8   3       2   3   1          2\n#> 9   3       3   5   0          7\n#> 10  4       1   7   0          9\n#> 11  4       2   3   1          2\n#> 12  4       3   7   0          9\n#> 13  5       1   5   0          7\n#> 14  5       2   3   1          2\n#> 15  5       3   5   0          7\n#> 16  6       1   6   0          8\n#> 17  6       2   3   3          2\n#> 18  6       3   6   0          8\n#> 19  7       1   4   0          6\n#> 20  7       2   3   1          3\n#> 21  7       3   5   0          7\n#> 22  8       1   4   0          6\n#> 23  8       2   3   3          2\n#> 24  8       3   4   0          6\n#> 25  9       1   5   0          7\n#> 26  9       2   1   0          3\n#> 27  9       3   5   0          7\n#> 28 10       1   5   0          7\n#> 29 10       2   4   2          2\n#> 30 10       3   5   0          7"},{"path":"evaluating-the-inferred-networks.html","id":"auprc","chapter":"6 Evaluating the inferred networks","heading":"6.3 AUPRC","text":"Although package focuses Bayesian network evaluation, commonly used metrics area precision-recall curve (AUPRC) can calculated. calc.auprc accepts reference bn object bn.strength object obtained bootstrapping, returns AUPRC value. function uses yardstick calculate value. target argument specifies column used weight, useful output software like GENIE3. example uses bootstrapped GES network inference calculates AUPRC.combining methods, possible determine network suitable assessment.","code":"\nnet <- readRDS(\"ecoli70.rds\")\ndata.inference <- rbn(net, 50)\ninfer <- pcalg.boot(data.inference, R=30)\ncalc.auprc(bn.net(net), infer)\n#> # A tibble: 1 × 3\n#>   .metric .estimator .estimate\n#>   <chr>   <chr>          <dbl>\n#> 1 pr_auc  binary         0.407"},{"path":"fitting-and-comparing-the-parameters.html","id":"fitting-and-comparing-the-parameters","chapter":"7 Fitting and comparing the parameters","heading":"7 Fitting and comparing the parameters","text":"","code":""},{"path":"fitting-and-comparing-the-parameters.html","id":"strucvalues-function","chapter":"7 Fitting and comparing the parameters","heading":"7.1 strucValues function","text":"selecting network, can fit parameters arcs obtained networks. analysis, strucValues function prepared. function enables comparison networks groups identifying regulatory relationships arcs cell group SCT data. function accepts network (bn tbl_graph) SingleCellExperiment data. labels specified interesting grouping.returns fitted parameters edge specified group.","code":"\nset.seed(1)\nlibrary(scstruc)\nsce <- mockSCE()\nsce <- logNormCounts(sce)\nincluded_genes <- sample(row.names(sce), 20)\ngs <- scstruc(sce, included_genes, changeSymbol=FALSE)\n\nsv <- strucValues(sce, labels=c(\"Treatment\"), bn = gs$net)\n#> Coefficient calculation per specified group: Treatment\nhead(sv)\n#>        from        to coefficient Treatment\n#> 1 Gene_0556 Gene_0816   0.3136802    treat1\n#> 2 Gene_0017 Gene_0909   0.1301085    treat1\n#> 3 Gene_0556 Gene_1647   0.2261649    treat1\n#> 4 Gene_0695 Gene_1794  -0.2075066    treat1\n#> 5 Gene_0017 Gene_1806  -0.2137052    treat1\n#> 6 Gene_1827 Gene_1806   0.2607372    treat1"},{"path":"fitting-and-comparing-the-parameters.html","id":"plotsubnet","chapter":"7 Fitting and comparing the parameters","heading":"7.2 plotSubNet","text":"plotSubNet plots network centered interesting genes based returned data.frame strucValues. plots separated specified label.","code":"\nlibrary(ggraph)\nplotSubNet(sv, sv$from[4], label = \"Treatment\")"},{"path":"fitting-and-comparing-the-parameters.html","id":"markercoefs-function","chapter":"7 Fitting and comparing the parameters","heading":"7.3 markerCoefs function","text":"marker arcs distinguishing groups can identified markerCoefs function. function accepts returned data.frame strucValues.cell_column cell_label used subset results based cell labels (.e. obtained cell clustering annotation). classif_label used specify group interest. sample_column specified additionally sample identifier information group interest.function default uses Boruta algorithm identifying candidate arcs.\nxgboost argument TRUE, classification performed R package xgboost.\nanalyses using algorithms, return_mat option allows output matrix actually used classification.","code":"\nmarks <- markerCoefs(sv, classif_label =  \"Treatment\", cell_column = NULL, sample_column = \"Treatment\")\n#> Performing Boruta algorithm ...\nmarks\n#> [[1]]\n#> Boruta performed 10 iterations in 0.4472868 secs.\n#>  No attributes deemed important.\n#>  7 attributes confirmed unimportant:\n#> Gene_0017->Gene_0909, Gene_0017->Gene_1806,\n#> Gene_0556->Gene_0816, Gene_0556->Gene_1647,\n#> Gene_0695->Gene_1794 and 2 more;\n#> \n#> [[2]]\n#> character(0)"},{"path":"plot.html","id":"plot","chapter":"8 Plotting functions","heading":"8 Plotting functions","text":"library various functions visualizing inferred networks highlighting important regulatory relationships comparing inferred networks multiple algorithms, using ggraph, tidygraph ggfx. can useful diagnosis publication figure. Mostly, function accepts bn object bnlearn.","code":""},{"path":"plot.html","id":"plotnet","chapter":"8 Plotting functions","heading":"8.1 plotNet","text":"plotNet function accepts bn object.Optionally, data can passed fit parameters function colors edge using fitted parameters. nodes sized degrees. degreeMode argument can specified degree calculated.","code":"\nlibrary(scstruc)\nsce <- mockSCE()\nsce <- logNormCounts(sce)\nincluded_genes <- sample(row.names(sce), 50)\ngs <- scstruc(sce, included_genes, changeSymbol=FALSE,\n    algorithm=\"glmnet_BIC\", returnData=TRUE)\n\n## Vanilla plot\nplotNet(gs$net)"},{"path":"plot.html","id":"plotavn","chapter":"8 Plotting functions","heading":"8.2 plotAVN","text":"function intended specifically visualizing bootstrapped networks. can pass results functions returning bn.strength object, function. threshold automatically determined specified. plot, strength shown edge width, direction shown edge color. node sizes determined degree.Edges can highlighted specifying highlightEdges argument, plotNet. plotAVN, with_outer_glow function ggfx package used highlight edges preserve strength direction mapping plot.","code":"\nlibrary(ggraph)\ngs.boot <- scstruc(sce, included_genes, changeSymbol=FALSE, boot=TRUE, R=10,\n             algorithm=\"glmnet_BIC\", returnData=TRUE)\n#> Bootstrapping specified\n\nplotAVN(gs.boot$net)"},{"path":"plot.html","id":"ggraph.compare","chapter":"8 Plotting functions","heading":"8.3 ggraph.compare","text":"Similar graphviz.compare function bnlearn, diagnostic plot can made ggraph.compare. accepts list bn object plot nodes edge associated graphs geom_edge_parallel. agreement edges multiple graphs can understood function, however, get complicated many graphs provided.","code":"\nggraph.compare(list(\"boot\"=averaged.network(gs.boot$net), \"raw\"=gs$net))"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
